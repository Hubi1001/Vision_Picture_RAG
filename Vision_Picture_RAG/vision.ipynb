{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1d4a83",
   "metadata": {},
   "source": [
    "# RAG dla materiaÅ‚Ã³w edukacyjnych z internetu (notatki, slajdy, wykresy)\n",
    "\n",
    "Ten notatnik pokazuje **system RAG** do wyszukiwania i analizy **materiaÅ‚Ã³w pobranych z internetu**:\n",
    "- ðŸ“„ Strony z PDF-Ã³w (wykÅ‚ady, artykuÅ‚y naukowe)\n",
    "- ðŸŽ¥ Screenshoty z YouTube/wykÅ‚adÃ³w online\n",
    "- ðŸ“Š Wykresy i diagramy z artykuÅ‚Ã³w\n",
    "- ðŸ–¼ï¸ Infografiki i schematy\n",
    "- ðŸ“‘ Slajdy z prezentacji\n",
    "\n",
    "## âš™ï¸ Optymalizacja dla GitHub Codespace (CPU)\n",
    "\n",
    "âœ… **Zoptymalizowane do dziaÅ‚ania na CPU**\n",
    "- Model embeddings: `paraphrase-multilingual-MiniLM-L12-v2` (~120MB)\n",
    "- Model LLM: `TinyLlama-1.1B-Chat` (~2GB RAM, dziaÅ‚a na CPU)\n",
    "- Baza danych: SQLite (fallback, bez wymagaÅ„ zewnÄ™trznych)\n",
    "- ObsÅ‚uga formatÃ³w: JPG, PNG, JPEG, WebP\n",
    "\n",
    "## ðŸ“‹ PLACEHOLDERY DO UZUPEÅNIENIA\n",
    "\n",
    "Przed uruchomieniem produkcyjnym uzupeÅ‚nij:\n",
    "\n",
    "1. **[PLACEHOLDER 1]** KomÃ³rka 3: `DATABASE_URL` - jeÅ›li uÅ¼ywasz PostgreSQL\n",
    "2. **[PLACEHOLDER 2]** KomÃ³rka 26: `notes_root` - Å›cieÅ¼ka do notatek tekstowych (podsumowania)\n",
    "3. **[PLACEHOLDER 3]** KomÃ³rka 26: `images_root` - Å›cieÅ¼ka do materiaÅ‚Ã³w z internetu\n",
    "4. **[PLACEHOLDER 4]** KomÃ³rka 26: `default_project_id` - ID projektu/kursu (np. \"ML-COURSE-2025\")\n",
    "5. **[PLACEHOLDER 5]** KomÃ³rka 14: `LLM_MODEL_NAME` - zmieÅ„ model jeÅ›li potrzebujesz innego\n",
    "\n",
    "## ðŸ·ï¸ Automatyczne tagowanie\n",
    "\n",
    "System rozpoznaje typy materiaÅ‚Ã³w po nazwie pliku:\n",
    "- `lecture_*` / `wyklad_*` â†’ **wykÅ‚ad**\n",
    "- `slide_*` / `slajd_*` â†’ **slajd**\n",
    "- `chart_*` / `wykres_*` â†’ **wykres**\n",
    "- `infographic_*` â†’ **infografika**\n",
    "- `youtube_*` / `yt_*` â†’ **youtube**\n",
    "- `arxiv_*` â†’ **arxiv**\n",
    "\n",
    "## Zawiera:\n",
    "\n",
    "1. DefinicjÄ™ modeli danych (materiaÅ‚y, notatki).\n",
    "2. Pipeline do:\n",
    "   - wczytania materiaÅ‚Ã³w z internetu (PNG/JPG/WebP)\n",
    "   - automatycznego tagowania (wykÅ‚ady, wykresy, YouTube, etc.)\n",
    "   - powiÄ…zania z notatkami tekstowymi\n",
    "   - wygenerowania embeddingÃ³w i zapisania w bazie\n",
    "3. ModuÅ‚ wyszukiwania (retriever) oparty na embeddingach i tagach.\n",
    "4. WarstwÄ™ RAG do odpowiadania na pytania o zgromadzone materiaÅ‚y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "082b032b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# === INSTALACJA PAKIETÃ“W (uruchom tylko raz) ===\n",
    "# Po uruchomieniu tej komÃ³rki, ZRESTARTUJ KERNEL przed uruchomieniem kolejnych komÃ³rek!\n",
    "# Instalacja w trakcie sesji moÅ¼e powodowaÄ‡ konflikty i awariÄ™ kernela.\n",
    "\n",
    "%pip install -q sentence-transformers transformers accelerate torch Pillow pgvector SQLAlchemy psycopg2-binary\n",
    "\n",
    "# Po zakoÅ„czeniu instalacji:\n",
    "# 1. Kliknij \"Kernel â†’ Restart Kernel\" (lub Ctrl+Shift+P â†’ \"Restart Kernel\")\n",
    "# 2. NastÄ™pnie uruchamiaj komÃ³rki po kolei od poczÄ…tku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8db410ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UÅ¼ywane urzÄ…dzenie: cpu\n",
      "Fallback: uÅ¼ywamy SQLite demo: sqlite:///./vision.db\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image as PILImage\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker, Session\n",
    "\n",
    "# === [PLACEHOLDER 1] DATABASE_URL ===\n",
    "# Dla GitHub Codespace: domyÅ›lnie SQLite (bez konfiguracji)\n",
    "# Dla PostgreSQL: ustaw zmiennÄ… Å›rodowiskowÄ… DATABASE_URL, np:\n",
    "#   export DATABASE_URL=\"postgresql://user:password@localhost:5432/vision_db\"\n",
    "# lub w Codespace: dodaj do secrets/env vars\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\", \"sqlite:///./vision.db\")\n",
    "USE_POSTGRES = DATABASE_URL.startswith(\"postgres\")\n",
    "\n",
    "# IMPORT ARRAY tylko jeÅ›li Å‚Ä…czymy siÄ™ z Postgres (unikamy bÅ‚Ä™dÃ³w dla SQLite)\n",
    "if USE_POSTGRES:\n",
    "    try:\n",
    "        from sqlalchemy.dialects.postgresql import ARRAY\n",
    "    except Exception:\n",
    "        ARRAY = None\n",
    "else:\n",
    "    ARRAY = None\n",
    "\n",
    "# pgvector (tylko jeÅ›li pracujesz na Postgresie i zainstalowanym pgvector)\n",
    "try:\n",
    "    if USE_POSTGRES:\n",
    "        from pgvector.sqlalchemy import Vector\n",
    "    else:\n",
    "        Vector = None\n",
    "except Exception:\n",
    "    Vector = None\n",
    "\n",
    "Base = declarative_base()\n",
    "engine = create_engine(DATABASE_URL, echo=False)\n",
    "SessionLocal = sessionmaker(bind=engine)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"UÅ¼ywane urzÄ…dzenie:\", DEVICE)\n",
    "if USE_POSTGRES:\n",
    "    print('DATABASE_URL wskazuje na Postgresa â€” upewnij siÄ™, Å¼e serwer dziaÅ‚a i ma rozszerzenie pgvector (jeÅ›li uÅ¼ywasz wektorÃ³w).')\n",
    "else:\n",
    "    print('Fallback: uÅ¼ywamy SQLite demo:', DATABASE_URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721959e4",
   "metadata": {},
   "source": [
    "## 1. Modele danych (obrazy, notatki, powiÄ…zania)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53ce5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, Float, DateTime, ForeignKey, JSON\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "class Image(Base):\n",
    "    __tablename__ = \"images\"\n",
    "\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    path = Column(String, nullable=False)\n",
    "    title = Column(String, nullable=True)\n",
    "\n",
    "    # Dla Postgresa: ARRAY(String) | Dla SQLite: JSON\n",
    "    if USE_POSTGRES and ARRAY is not None:\n",
    "        tags = Column(ARRAY(String), nullable=True)\n",
    "    else:\n",
    "        tags = Column(JSON, nullable=True)\n",
    "\n",
    "    project_id = Column(String, nullable=True)\n",
    "    experiment_id = Column(String, nullable=True)\n",
    "\n",
    "    capture_time = Column(DateTime, nullable=True)\n",
    "    camera_model = Column(String, nullable=True)\n",
    "    iso = Column(Integer, nullable=True)\n",
    "    aperture = Column(Float, nullable=True)\n",
    "    focal_length = Column(Float, nullable=True)\n",
    "    gps_lat = Column(Float, nullable=True)\n",
    "    gps_lng = Column(Float, nullable=True)\n",
    "\n",
    "    # Kolumna na embedding tekstowy (pgvector)\n",
    "    if 'Vector' in globals() and Vector is not None:\n",
    "        text_embedding = Column(Vector(768), nullable=True)  # 768 wymiarÃ³w dla MiniLM\n",
    "    else:\n",
    "        # Fallback â€“ jeÅ›li nie uÅ¼ywasz pgvector, moÅ¼esz trzymaÄ‡ embedding np. jako tekst JSON\n",
    "        text_embedding = Column(String, nullable=True)\n",
    "\n",
    "    notes = relationship(\"ImageNote\", back_populates=\"image\")\n",
    "\n",
    "\n",
    "class Note(Base):\n",
    "    __tablename__ = \"notes\"\n",
    "\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    experiment_id = Column(String, nullable=True)\n",
    "    language = Column(String, nullable=True)\n",
    "    text = Column(String, nullable=False)\n",
    "\n",
    "    images = relationship(\"ImageNote\", back_populates=\"note\")\n",
    "\n",
    "\n",
    "class ImageNote(Base):\n",
    "    __tablename__ = \"image_notes\"\n",
    "\n",
    "    image_id = Column(Integer, ForeignKey(\"images.id\"), primary_key=True)\n",
    "    note_id = Column(Integer, ForeignKey(\"notes.id\"), primary_key=True)\n",
    "\n",
    "    image = relationship(\"Image\", back_populates=\"notes\")\n",
    "    note = relationship(\"Note\", back_populates=\"images\")\n",
    "\n",
    "\n",
    "def create_tables() -> None:\n",
    "    \"\"\"UtwÃ³rz tabele w bazie danych (wywoÅ‚aj raz).\"\"\"\n",
    "    Base.metadata.create_all(engine)\n",
    "    print(\"Tabele zostaÅ‚y utworzone (lub juÅ¼ istniaÅ‚y).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "658c0306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabele zostaÅ‚y utworzone (lub juÅ¼ istniaÅ‚y).\n",
      "PoÅ‚Ä…czenie z bazÄ… dziaÅ‚a, SessionLocal OK.\n",
      "Liczba obrazÃ³w: 3\n",
      "Liczba notatek: 2\n",
      "Liczba powiÄ…zaÅ„: 3\n"
     ]
    }
   ],
   "source": [
    "# Test 1: poÅ‚Ä…czenie z bazÄ… + tworzenie tabel\n",
    "create_tables()\n",
    "\n",
    "with SessionLocal() as db:\n",
    "    print(\"PoÅ‚Ä…czenie z bazÄ… dziaÅ‚a, SessionLocal OK.\")\n",
    "    print(\"Liczba obrazÃ³w:\", db.query(Image).count())\n",
    "    print(\"Liczba notatek:\", db.query(Note).count())\n",
    "    print(\"Liczba powiÄ…zaÅ„:\", db.query(ImageNote).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8351563d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabele zostaÅ‚y utworzone (lub juÅ¼ istniaÅ‚y).\n",
      "PoÅ‚Ä…czenie z bazÄ… dziaÅ‚a, SessionLocal OK.\n",
      "Liczba obrazÃ³w: 3\n",
      "Liczba notatek: 2\n",
      "Liczba powiÄ…zaÅ„: 3\n"
     ]
    }
   ],
   "source": [
    "# Test 1: poÅ‚Ä…czenie z bazÄ… + tworzenie tabel\n",
    "create_tables()\n",
    "\n",
    "with SessionLocal() as db:\n",
    "    print(\"PoÅ‚Ä…czenie z bazÄ… dziaÅ‚a, SessionLocal OK.\")\n",
    "    print(\"Liczba obrazÃ³w:\", db.query(Image).count())\n",
    "    print(\"Liczba notatek:\", db.query(Note).count())\n",
    "    print(\"Liczba powiÄ…zaÅ„:\", db.query(ImageNote).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd3ada",
   "metadata": {},
   "source": [
    "## 2. Pipeline indeksowania: obrazy + EXIF + notatki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e03e7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_exif(path: Path) -> dict:\n",
    "    \"\"\"WyciÄ…ga EXIF z obrazu jako sÅ‚ownik.\"\"\"\n",
    "    img = PILImage.open(path)\n",
    "    exif_raw = getattr(img, \"_getexif\", lambda: None)() or {}\n",
    "    exif: dict = {}\n",
    "    for tag_id, value in exif_raw.items():\n",
    "        tag = TAGS.get(tag_id, tag_id)\n",
    "        exif[tag] = value\n",
    "    return exif\n",
    "\n",
    "\n",
    "def exif_to_fields(exif: dict) -> dict:\n",
    "    \"\"\"Mapuje surowy EXIF do pÃ³l, ktÃ³re chcemy trzymaÄ‡ w bazie.\"\"\"\n",
    "    fields: dict = {}\n",
    "\n",
    "    fields[\"camera_model\"] = exif.get(\"Model\")\n",
    "    fields[\"iso\"] = exif.get(\"ISOSpeedRatings\") or exif.get(\"ISO\")\n",
    "    fields[\"focal_length\"] = exif.get(\"FocalLength\")\n",
    "    fields[\"aperture\"] = exif.get(\"FNumber\")\n",
    "\n",
    "    # TODO: dodaj parsowanie capture_time, GPS itd. jeÅ›li potrzebujesz\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e87a111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_note_text_from_file(path: Path) -> str:\n",
    "    \"\"\"Åaduje tekst notatki z pliku (np. .txt / .md).\"\"\"\n",
    "    return path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def index_notes_from_folder(\n",
    "    db: Session,\n",
    "    notes_root: Path,\n",
    "    experiment_id_from_name: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"Indeksuje notatki z folderu w bazie.\n",
    "\n",
    "    ZakÅ‚adamy, Å¼e id eksperymentu moÅ¼na wydobyÄ‡ z nazwy pliku,\n",
    "    np. 'EXP-2025-01_notatka1.md' â†’ 'EXP-2025-01'.\n",
    "    \"\"\"\n",
    "    for note_path in notes_root.rglob(\"*.md\"):\n",
    "        text = load_note_text_from_file(note_path)\n",
    "\n",
    "        if experiment_id_from_name:\n",
    "            exp_id = note_path.stem.split(\"_\")[0]\n",
    "        else:\n",
    "            exp_id = None\n",
    "\n",
    "        note = Note(\n",
    "            experiment_id=exp_id,\n",
    "            language=\"pl\",\n",
    "            text=text,\n",
    "        )\n",
    "        db.add(note)\n",
    "\n",
    "    db.commit()\n",
    "    print(\"Zindeksowano notatki z folderu:\", notes_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51779aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_images_from_folder(\n",
    "    db: Session,\n",
    "    images_root: Path,\n",
    "    default_project_id: Optional[str] = None,\n",
    "    experiment_id_from_folder: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"Indeksuje pliki .jpg ze zdjÄ™ciami notatek z internetu.\n",
    "    \n",
    "    ObsÅ‚uguje:\n",
    "    - ZdjÄ™cia slajdÃ³w PDF-Ã³w z wykÅ‚adÃ³w\n",
    "    - Screenshoty z YouTube/webinarÃ³w\n",
    "    - Fotografie tablic biaÅ‚ych/czarnych\n",
    "    - Skany dokumentÃ³w/protokoÅ‚Ã³w\n",
    "    - Wykresy i diagramy z artykuÅ‚Ã³w\n",
    "    \"\"\"\n",
    "    # Szukamy wyÅ‚Ä…cznie plikÃ³w .jpg\n",
    "    for img_path in images_root.rglob(\"*.jpg\"):\n",
    "        try:\n",
    "            exif = extract_exif(img_path)\n",
    "            fields = exif_to_fields(exif)\n",
    "        except Exception:\n",
    "            # ZdjÄ™cia z internetu rzadko majÄ… EXIF - to normalne\n",
    "            fields = {}\n",
    "\n",
    "        if experiment_id_from_folder:\n",
    "            exp_id = img_path.parent.name\n",
    "        else:\n",
    "            exp_id = None\n",
    "        \n",
    "        # Automatyczne tagowanie na podstawie nazwy pliku\n",
    "        auto_tags = []\n",
    "        filename_lower = img_path.stem.lower()\n",
    "        \n",
    "        # Tagi tematyczne\n",
    "        if any(word in filename_lower for word in [\"lecture\", \"wyklad\", \"presentation\", \"prezentacja\"]):\n",
    "            auto_tags.append(\"wykÅ‚ad\")\n",
    "        if any(word in filename_lower for word in [\"slide\", \"slajd\", \"page\"]):\n",
    "            auto_tags.append(\"slajd\")\n",
    "        if any(word in filename_lower for word in [\"chart\", \"graph\", \"wykres\", \"diagram\"]):\n",
    "            auto_tags.append(\"wykres\")\n",
    "        if any(word in filename_lower for word in [\"infographic\", \"infografika\", \"schema\", \"schemat\"]):\n",
    "            auto_tags.append(\"infografika\")\n",
    "        if any(word in filename_lower for word in [\"note\", \"notatka\", \"summary\", \"podsumowanie\"]):\n",
    "            auto_tags.append(\"notatki\")\n",
    "        if any(word in filename_lower for word in [\"screenshot\", \"zrzut\", \"screen\"]):\n",
    "            auto_tags.append(\"screenshot\")\n",
    "        \n",
    "        # Tagi ÅºrÃ³dÅ‚owe\n",
    "        if \"youtube\" in filename_lower or \"yt\" in filename_lower:\n",
    "            auto_tags.append(\"youtube\")\n",
    "        if \"pdf\" in filename_lower:\n",
    "            auto_tags.append(\"pdf\")\n",
    "        if \"arxiv\" in filename_lower:\n",
    "            auto_tags.append(\"arxiv\")\n",
    "        \n",
    "        # JeÅ›li brak tagÃ³w, dodaj uniwersalny\n",
    "        if not auto_tags:\n",
    "            auto_tags.append(\"materiaÅ‚\")\n",
    "\n",
    "        image = Image(\n",
    "            path=str(img_path),\n",
    "            title=img_path.stem,\n",
    "            tags=auto_tags,\n",
    "            project_id=default_project_id,\n",
    "            experiment_id=exp_id,\n",
    "            camera_model=fields.get(\"camera_model\"),\n",
    "            iso=fields.get(\"iso\"),\n",
    "            aperture=fields.get(\"aperture\"),\n",
    "            focal_length=fields.get(\"focal_length\"),\n",
    "        )\n",
    "        db.add(image)\n",
    "\n",
    "    db.commit()\n",
    "    print(\"Zindeksowano pliki .jpg z folderu:\", images_root)\n",
    "\n",
    "    db.commit()\n",
    "    print(\"Zindeksowano obrazy z folderu:\", images_root)\n",
    "\n",
    "\n",
    "def link_images_to_notes_by_experiment(db: Session) -> None:\n",
    "    \"\"\"ÅÄ…czy obrazy i notatki po experiment_id (prosty wariant).\"\"\"\n",
    "    images = db.query(Image).all()\n",
    "    notes = db.query(Note).all()\n",
    "\n",
    "    notes_by_exp: dict[str, list[Note]] = {}\n",
    "    for note in notes:\n",
    "        if note.experiment_id:\n",
    "            notes_by_exp.setdefault(note.experiment_id, []).append(note)\n",
    "\n",
    "    for img in images:\n",
    "        if not img.experiment_id:\n",
    "            continue\n",
    "\n",
    "        for note in notes_by_exp.get(img.experiment_id, []):\n",
    "            existing = (\n",
    "                db.query(ImageNote)\n",
    "                .filter_by(image_id=img.id, note_id=note.id)\n",
    "                .first()\n",
    "            )\n",
    "            if existing is None:\n",
    "                db.add(ImageNote(image_id=img.id, note_id=note.id))\n",
    "\n",
    "    db.commit()\n",
    "    print(\"PoÅ‚Ä…czono obrazy z notatkami po experiment_id.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6360a9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba obrazÃ³w: 3\n",
      "Liczba notatek: 2\n",
      "Liczba powiÄ…zaÅ„ (image_notes): 3\n",
      "PrzykÅ‚adowy obraz:\n",
      "  ID: 1\n",
      "  ÅšcieÅ¼ka: obrazy/img1.jpg\n",
      "  Eksperyment: EXP-2025-01\n"
     ]
    }
   ],
   "source": [
    "# Test 2: sprawdÅº efekty indeksowania obrazÃ³w i notatek\n",
    "\n",
    "with SessionLocal() as db:\n",
    "    images_count = db.query(Image).count()\n",
    "    notes_count = db.query(Note).count()\n",
    "    links_count = db.query(ImageNote).count()\n",
    "    print(\"Liczba obrazÃ³w:\", images_count)\n",
    "    print(\"Liczba notatek:\", notes_count)\n",
    "    print(\"Liczba powiÄ…zaÅ„ (image_notes):\", links_count)\n",
    "\n",
    "    example_img = db.query(Image).first()\n",
    "    if example_img:\n",
    "        print(\"PrzykÅ‚adowy obraz:\")\n",
    "        print(\"  ID:\", example_img.id)\n",
    "        print(\"  ÅšcieÅ¼ka:\", example_img.path)\n",
    "        print(\"  Eksperyment:\", example_img.experiment_id)\n",
    "    else:\n",
    "        print(\"Brak obrazÃ³w w bazie â€“ upewnij siÄ™, Å¼e masz dane (syntetyczne lub z plikÃ³w).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f9f04",
   "metadata": {},
   "source": [
    "## 3. Modele: embeddingi (MiniLM) i LLM (Qwen2.5-1.5B-Instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de50328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Odmowa dostÄ™pu: 'c:\\\\Users\\\\hubik\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\mlir\\\\lite\\\\python\\\\_pywrap_converter_api.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_USE_LEGACY_KERAS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Teraz moÅ¼na bezpiecznie importowaÄ‡\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# === Konfiguracja modelu embeddingowego ===\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\__init__.py:15\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     13\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     CrossEncoder,\n\u001b[0;32m     17\u001b[0m     CrossEncoderModelCardData,\n\u001b[0;32m     18\u001b[0m     CrossEncoderTrainer,\n\u001b[0;32m     19\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfit_mixin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FitMixin\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData, generate_model_card\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     cross_encoder_init_args_decorator,\n\u001b[0;32m     33\u001b[0m     cross_encoder_predict_rank_args_decorator,\n\u001b[0;32m     34\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\fit_mixin.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputExample\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\datasets\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParallelSentencesDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentencesDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\datasets\\ParallelSentencesDataset.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module, get_relative_import_files\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Router\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mModule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\model_card.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainerCallback\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CodeCarbonCallback\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_markdown_table\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_callback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainerControl, TrainerState\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2292\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2292\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2293\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2294\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2322\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2320\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2319\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2321\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2322\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py:44\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_MODE\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffline\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš™ï¸  Running in WANDB offline mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel, TrainingArguments\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     PushToHubMixin,\n\u001b[0;32m     48\u001b[0m     flatten_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     logging,\n\u001b[0;32m     54\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2292\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2292\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2293\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2294\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2322\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2320\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2319\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2321\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2322\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n",
      "File \u001b[1;32mc:\\Users\\hubik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_gelu\u001b[39m(x):\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    Gaussian Error Linear Unit. Original Implementation of the gelu activation function in Google Bert repo when\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    initially created. For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) Also see\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    https://huggingface.co/papers/1606.08415\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "# UWAGA: JeÅ›li instalowaÅ‚eÅ› pakiety w tej sesji kernela, zrestartuj kernel (Kernel â†’ Restart) przed importami.\n",
    "# Instalacja w trakcie sesji moÅ¼e powodowaÄ‡ konflikty i awariÄ™ kernela.\n",
    "\n",
    "# WyÅ‚Ä…cz backend TensorFlow w Transformers, aby nie wymagaÅ‚ tf-keras (unikamy bÅ‚Ä™du Keras 3)\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "# Teraz moÅ¼na bezpiecznie importowaÄ‡\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# === Konfiguracja modelu embeddingowego ===\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=DEVICE)\n",
    "print(\"ZaÅ‚adowano model embeddingowy:\", EMBEDDING_MODEL_NAME)\n",
    "\n",
    "# === Konfiguracja modelu LLM ===\n",
    "# === [PLACEHOLDER 5] WybÃ³r modelu LLM ===\n",
    "# DomyÅ›lnie: TinyLlama (zoptymalizowany dla CPU, ~2GB RAM)\n",
    "LLM_MODEL_CANDIDATES = [\n",
    "    \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",  # âœ… REKOMENDOWANE dla Codespace/CPU\n",
    "    \"gpt2\",  # ~500MB, tylko angielski (backup)\n",
    "    \"distilgpt2\",  # ~350MB, szybszy, tylko angielski\n",
    "]\n",
    "\n",
    "llm_model = None\n",
    "tokenizer = None\n",
    "\n",
    "for candidate in LLM_MODEL_CANDIDATES:\n",
    "    try:\n",
    "        print(f\"Åadowanie modelu LLM: {candidate} (moÅ¼e potrwaÄ‡ kilka minut)...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(candidate)\n",
    "        llm_model = AutoModelForCausalLM.from_pretrained(candidate, low_cpu_mem_usage=True)\n",
    "        llm_model.to(DEVICE)\n",
    "        tokenizer.padding_side = \"left\"\n",
    "\n",
    "        # Dodaj pad_token jeÅ›li nie istnieje (potrzebne dla niektÃ³rych modeli)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        print(\"âœ“ ZaÅ‚adowano model LLM:\", candidate)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— BÅÄ„D podczas Å‚adowania LLM {candidate}: {e}\")\n",
    "        print(\"PrÃ³ba kolejnego modelu (mniejszy / lÅ¼ejszy)...\")\n",
    "        llm_model = None\n",
    "        tokenizer = None\n",
    "        continue\n",
    "\n",
    "if llm_model is None or tokenizer is None:\n",
    "    print(\"Nie udaÅ‚o siÄ™ zaÅ‚adowaÄ‡ Å¼adnego modelu LLM z listy LLM_MODEL_CANDIDATES.\")\n",
    "    print(\"MoÅ¼liwe przyczyny:\")\n",
    "    print(\"  - Brak pamiÄ™ci RAM (model wymaga ~4-6GB)\")\n",
    "    print(\"  - BÅ‚Ä…d pobierania z Hugging Face\")\n",
    "    print(\"\\nRozwiÄ…zania:\")\n",
    "    print(\"  1. UÅ¼yj mniejszego modelu (np. TinyLlama lub gpt2)\")\n",
    "    print(\"  2. ZwiÄ™ksz pamiÄ™Ä‡ kontenera/VM\")\n",
    "    print(\"  3. PomiÅ„ funkcje RAG wymagajÄ…ce LLM (uÅ¼yj tylko wyszukiwania)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: szybki test embeddingÃ³w (bez bazy)\n",
    "\n",
    "test_text = \"To jest przykÅ‚adowa notatka z eksperymentu o wysokiej temperaturze.\"\n",
    "emb = get_embedding(test_text) if 'get_embedding' in globals() else None\n",
    "\n",
    "if emb is None:\n",
    "    print(\"Funkcja get_embedding jeszcze nie jest zdefiniowana â€“ uruchom najpierw komÃ³rkÄ™ z jej definicjÄ….\")\n",
    "else:\n",
    "    print(\"DÅ‚ugoÅ›Ä‡ embeddingu:\", len(emb))\n",
    "    print(\"Pierwsze 5 wartoÅ›ci:\", emb[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8385c7c",
   "metadata": {},
   "source": [
    "## 4. Tekst do embeddingÃ³w i funkcja `get_embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_text(db: Session, image: Image) -> str:\n",
    "    \"\"\"Buduje tekstowy opis obrazu na podstawie metadanych i notatek.\"\"\"\n",
    "    links = db.query(ImageNote).filter_by(image_id=image.id).all()\n",
    "    note_ids = [ln.note_id for ln in links]\n",
    "\n",
    "    notes: List[Note] = []\n",
    "    if note_ids:\n",
    "        notes = db.query(Note).filter(Note.id.in_(note_ids)).all()\n",
    "\n",
    "    notes_text = \"\\n\\n---\\n\\n\".join(n.text for n in notes[:3])  # max 3 notatki\n",
    "\n",
    "    tags_str = \", \".join(image.tags or [])\n",
    "    exif_summary_parts: list[str] = []\n",
    "\n",
    "    if image.camera_model:\n",
    "        exif_summary_parts.append(f\"Model aparatu: {image.camera_model}\")\n",
    "    if image.iso is not None:\n",
    "        exif_summary_parts.append(f\"ISO: {image.iso}\")\n",
    "    if image.focal_length is not None:\n",
    "        exif_summary_parts.append(f\"Ogniskowa: {image.focal_length}mm\")\n",
    "    if image.aperture is not None:\n",
    "        exif_summary_parts.append(f\"PrzysÅ‚ona: {image.aperture}\")\n",
    "\n",
    "    exif_summary = \", \".join(exif_summary_parts)\n",
    "\n",
    "    base = f\"\"\"TytuÅ‚: {image.title or ''}\n",
    "Tagi: {tags_str}\n",
    "Projekt: {image.project_id or ''}\n",
    "Eksperyment: {image.experiment_id or ''}\n",
    "Parametry: {exif_summary}\n",
    "\"\"\"\n",
    "\n",
    "    if notes_text:\n",
    "        return base + \"\\n\\nNotatki:\\n\" + notes_text\n",
    "    return base\n",
    "\n",
    "\n",
    "def get_embedding(text: str) -> list[float]:\n",
    "    \"\"\"Zwraca embedding tekstu korzystajÄ…c z SentenceTransformer (MiniLM).\"\"\"\n",
    "    emb = embedding_model.encode(text, normalize_embeddings=True)\n",
    "    return emb.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a68f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_embeddings(db: Session) -> None:\n",
    "    \"\"\"Generuje embeddingi tekstowe dla wszystkich obrazÃ³w i zapisuje w bazie.\"\"\"\n",
    "    images = db.query(Image).all()\n",
    "\n",
    "    for img in images:\n",
    "        text = build_image_text(db, img)\n",
    "        emb = get_embedding(text)\n",
    "\n",
    "        if Vector is not None:\n",
    "            img.text_embedding = emb  # pgvector przyjmie listÄ™ floatÃ³w\n",
    "        else:\n",
    "            # Fallback â€“ zapis jako tekst (np. do dalszego uÅ¼ycia w Pythonie)\n",
    "            img.text_embedding = \";\".join(str(x) for x in emb)\n",
    "\n",
    "    db.commit()\n",
    "    print(\"Zaktualizowano embeddingi dla\", len(images), \"obrazÃ³w.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: embeddingi w bazie\n",
    "\n",
    "with SessionLocal() as db:\n",
    "    img = db.query(Image).first()\n",
    "    if img is None:\n",
    "        print(\"Brak obrazÃ³w w bazie â€“ nic nie moÅ¼na sprawdziÄ‡.\")\n",
    "    else:\n",
    "        print(\"Obraz ID:\", img.id)\n",
    "        print(\"ÅšcieÅ¼ka:\", img.path)\n",
    "        print(\"Eksperyment:\", img.experiment_id)\n",
    "        print(\"Pole text_embedding (przyciÄ™te do 120 znakÃ³w):\")\n",
    "        print(str(img.text_embedding)[:120], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2135d9ca",
   "metadata": {},
   "source": [
    "## 5. Retriever: wyszukiwanie obrazÃ³w po embeddingach i metadanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de838447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_images(\n",
    "    db: Session,\n",
    "    query: str,\n",
    "    project_id: Optional[str] = None,\n",
    "    experiment_id: Optional[str] = None,\n",
    "    limit: int = 10,\n",
    ") -> List[Image]:\n",
    "    \"\"\"Zwraca listÄ™ obrazÃ³w pasujÄ…cych do zapytania.\"\"\"\n",
    "    q_emb = get_embedding(query)\n",
    "\n",
    "    base_query = db.query(Image)\n",
    "    if project_id:\n",
    "        base_query = base_query.filter(Image.project_id == project_id)\n",
    "    if experiment_id:\n",
    "        base_query = base_query.filter(Image.experiment_id == experiment_id)\n",
    "\n",
    "    if Vector is not None:\n",
    "        # UÅ¼ywamy operatora l2_distance (lub cosine_distance, jeÅ›li skonfigurowany)\n",
    "        base_query = base_query.order_by(Image.text_embedding.l2_distance(q_emb))\n",
    "        images = base_query.limit(limit).all()\n",
    "        return images\n",
    "\n",
    "    # Fallback â€“ jeÅ›li nie ma pgvector, moÅ¼emy na szybko zwrÃ³ciÄ‡ pierwsze N\n",
    "    all_images = base_query.all()\n",
    "    return all_images[:limit]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5721e6a",
   "metadata": {},
   "source": [
    "## 6. Warstwa RAG: budowanie kontekstu i wywoÅ‚anie LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_notes_text(text: str, max_chars: int = 800) -> str:\n",
    "    \"\"\"Bardzo prosty skrÃ³t notatek (obciÄ™cie do max_chars).\"\"\"\n",
    "    if len(text) <= max_chars:\n",
    "        return text\n",
    "    return text[: max_chars - 3] + \"...\"\n",
    "\n",
    "\n",
    "def build_context_for_llm(db: Session, images: List[Image]) -> str:\n",
    "    \"\"\"Buduje tekstowy kontekst dla LLM na podstawie obrazÃ³w i ich notatek.\"\"\"\n",
    "    parts: list[str] = []\n",
    "\n",
    "    for img in images:\n",
    "        links = db.query(ImageNote).filter_by(image_id=img.id).all()\n",
    "        note_ids = [ln.note_id for ln in links]\n",
    "\n",
    "        notes: List[Note] = []\n",
    "        if note_ids:\n",
    "            notes = db.query(Note).filter(Note.id.in_(note_ids)).all()\n",
    "\n",
    "        notes_short: list[str] = []\n",
    "        for n in notes[:3]:\n",
    "            notes_short.append(summarize_notes_text(n.text, max_chars=600))\n",
    "\n",
    "        notes_joined = \"\\n\\n\".join(notes_short)\n",
    "        tags_str = \", \".join(img.tags or [])\n",
    "\n",
    "        part = f\"\"\"[OBRAZ {img.id}]\n",
    "ÅšcieÅ¼ka: {img.path}\n",
    "Projekt: {img.project_id or ''}, Eksperyment: {img.experiment_id or ''}\n",
    "Tagi: {tags_str}\n",
    "Parametry: ISO {img.iso}, ogniskowa {img.focal_length}, przysÅ‚ona {img.aperture}\n",
    "\n",
    "Notatki (skrÃ³t):\n",
    "{notes_joined}\n",
    "\"\"\"\n",
    "        parts.append(part)\n",
    "\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)\n",
    "\n",
    "\n",
    "def chat_completion(prompt: str) -> str:\n",
    "    \"\"\"WywoÅ‚uje model LLM i zwraca odpowiedÅº tekstowÄ….\n",
    "    \n",
    "    JeÅ›li LLM nie zaÅ‚adowaÅ‚ siÄ™ (llm_model is None), zwraca informacjÄ™ o bÅ‚Ä™dzie.\n",
    "    \"\"\"\n",
    "    if llm_model is None or tokenizer is None:\n",
    "        return \"[BÅÄ„D: Model LLM nie zostaÅ‚ zaÅ‚adowany. SprawdÅº komunikaty z komÃ³rki Å‚adowania modelu.]\"\n",
    "    \n",
    "    # Prosty format promptu (dziaÅ‚a z wiÄ™kszoÅ›ciÄ… modeli)\n",
    "    system_text = \"JesteÅ› pomocnym asystentem, odpowiadasz po polsku.\"\n",
    "    full_prompt = system_text + \"\\n\\n\" + prompt\n",
    "    \n",
    "    # Tokenizacja\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\", padding=True)\n",
    "    input_ids = inputs[\"input_ids\"].to(DEVICE)\n",
    "    attention_mask = inputs.get(\"attention_mask\")\n",
    "    if attention_mask is not None:\n",
    "        attention_mask = attention_mask.to(DEVICE)\n",
    "    \n",
    "    # Generowanie\n",
    "    with torch.no_grad():\n",
    "        gen_kwargs = dict(\n",
    "            input_ids=input_ids,\n",
    "            max_new_tokens=384,\n",
    "            do_sample=False,\n",
    "            temperature=1.0,\n",
    "            top_p=1.0,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "        if attention_mask is not None:\n",
    "            gen_kwargs[\"attention_mask\"] = attention_mask\n",
    "        \n",
    "        outputs = llm_model.generate(**gen_kwargs)\n",
    "    \n",
    "    # Dekodowanie tylko nowo wygenerowanych tokenÃ³w\n",
    "    generated_ids = outputs[0, input_ids.shape[-1]:]\n",
    "    text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def answer_question(\n",
    "    db: Session,\n",
    "    question: str,\n",
    "    limit_images: int = 5,\n",
    ") -> dict:\n",
    "    \"\"\"GÅ‚Ã³wna funkcja RAG.\n",
    "\n",
    "    1. Wyszukuje obrazy pasujÄ…ce do pytania.\n",
    "    2. Buduje kontekst.\n",
    "    3. WywoÅ‚uje LLM z pytaniem + kontekstem.\n",
    "    4. Zwraca odpowiedÅº i listÄ™ ID obrazÃ³w.\n",
    "    \"\"\"\n",
    "    images = search_images(db, question, limit=limit_images)\n",
    "    context = build_context_for_llm(db, images)\n",
    "\n",
    "    prompt = f\"\"\"JesteÅ› asystentem analizujÄ…cym wyniki eksperymentÃ³w na podstawie obrazÃ³w i notatek.\n",
    "Odpowiadasz po polsku, rzeczowo, powoÅ‚ujÄ…c siÄ™ na ID obrazÃ³w w nawiasach kwadratowych.\n",
    "\n",
    "Pytanie uÅ¼ytkownika:\n",
    "{question}\n",
    "\n",
    "DostÄ™pne obrazy i notatki:\n",
    "{context}\n",
    "\n",
    "Na podstawie tych danych:\n",
    "1. Odpowiedz na pytanie.\n",
    "2. JeÅ›li to moÅ¼liwe, wskaÅ¼, ktÃ³re obrazy sÄ… kluczowe (podaj [OBRAZ ID]).\n",
    "\"\"\"\n",
    "\n",
    "    answer_text = chat_completion(prompt)\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer_text,\n",
    "        \"image_ids\": [img.id for img in images],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cdcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: mini RAG end-to-end (wyszukiwanie materiaÅ‚Ã³w z internetu)\n",
    "\n",
    "test_question = \"PokaÅ¼ materiaÅ‚y o gradient descent i optymalizacji\"\n",
    "\n",
    "with SessionLocal() as db:\n",
    "    result = answer_question(db, test_question, limit_images=3)\n",
    "\n",
    "print(\"ODPOWIEDÅ¹:\\n\")\n",
    "print(result[\"answer\"])\n",
    "print(\"\\nZnalezione materiaÅ‚y (IDs):\", result[\"image_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b94015",
   "metadata": {},
   "source": [
    "## 7. PrzykÅ‚adowe uÅ¼ycie (uruchamiane krok po kroku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PRZYKÅADOWE UÅ»YCIE Z DANYMI TESTOWYMI ===\n",
    "# Uruchom tÄ™ komÃ³rkÄ™, aby stworzyÄ‡ syntetyczne dane i przetestowaÄ‡ system\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. UtwÃ³rz tabele\n",
    "    create_tables()\n",
    "\n",
    "    with SessionLocal() as db:\n",
    "        # === OPCJA A: DANE TESTOWE (syntetyczne) ===\n",
    "        # Odkomentuj poniÅ¼sze linie, aby stworzyÄ‡ przykÅ‚adowe dane bez plikÃ³w:\n",
    "        \n",
    "        # # StwÃ³rz przykÅ‚adowe materiaÅ‚y z internetu\n",
    "        # test_img1 = Image(\n",
    "        #     path=\"obrazy/machine_learning/lecture_03_slide_15.png\",\n",
    "        #     title=\"Machine Learning - Gradient Descent explained\",\n",
    "        #     tags=[\"wykÅ‚ad\", \"slajd\", \"machine-learning\", \"pdf\"],\n",
    "        #     project_id=\"ML-COURSE-2025\",\n",
    "        #     experiment_id=\"TOPIC-OPTIMIZATION\"\n",
    "        # )\n",
    "        # db.add(test_img1)\n",
    "        # \n",
    "        # test_img2 = Image(\n",
    "        #     path=\"obrazy/deep_learning/youtube_screenshot_backprop.jpg\",\n",
    "        #     title=\"3Blue1Brown - Backpropagation explained\",\n",
    "        #     tags=[\"youtube\", \"screenshot\", \"deep-learning\", \"wykres\"],\n",
    "        #     project_id=\"ML-COURSE-2025\",\n",
    "        #     experiment_id=\"TOPIC-NEURAL-NETS\"\n",
    "        # )\n",
    "        # db.add(test_img2)\n",
    "        # \n",
    "        # test_img3 = Image(\n",
    "        #     path=\"obrazy/statistics/infographic_distributions.png\",\n",
    "        #     title=\"Statistical Distributions Cheat Sheet\",\n",
    "        #     tags=[\"infografika\", \"statystyka\", \"wykres\"],\n",
    "        #     project_id=\"STATS-REFERENCE\",\n",
    "        #     experiment_id=\"TOPIC-PROBABILITY\"\n",
    "        # )\n",
    "        # db.add(test_img3)\n",
    "        # \n",
    "        # test_img4 = Image(\n",
    "        #     path=\"obrazy/algorithms/arxiv_paper_fig3.png\",\n",
    "        #     title=\"Novel sorting algorithm - complexity chart\",\n",
    "        #     tags=[\"arxiv\", \"wykres\", \"algorytmy\", \"pdf\"],\n",
    "        #     project_id=\"RESEARCH-2025\",\n",
    "        #     experiment_id=\"TOPIC-ALGORITHMS\"\n",
    "        # )\n",
    "        # db.add(test_img4)\n",
    "        # db.commit()\n",
    "        # \n",
    "        # # StwÃ³rz przykÅ‚adowe notatki tekstowe (podsumowania z internetu)\n",
    "        # test_note1 = Note(\n",
    "        #     experiment_id=\"TOPIC-OPTIMIZATION\",\n",
    "        #     language=\"pl\",\n",
    "        #     text=\"Gradient descent - algorytm optymalizacji. Kluczowe parametry: learning rate, momentum. \"\n",
    "        #          \"MateriaÅ‚ z kursu Andrew Ng na Coursera.\"\n",
    "        # )\n",
    "        # db.add(test_note1)\n",
    "        # \n",
    "        # test_note2 = Note(\n",
    "        #     experiment_id=\"TOPIC-NEURAL-NETS\",\n",
    "        #     language=\"pl\",\n",
    "        #     text=\"Backpropagation - propagacja wsteczna bÅ‚Ä™du w sieciach neuronowych. \"\n",
    "        #          \"WyjaÅ›nienie wizualne z kanaÅ‚u 3Blue1Brown na YouTube.\"\n",
    "        # )\n",
    "        # db.add(test_note2)\n",
    "        # \n",
    "        # test_note3 = Note(\n",
    "        #     experiment_id=\"TOPIC-PROBABILITY\",\n",
    "        #     language=\"pl\",\n",
    "        #     text=\"RozkÅ‚ady statystyczne: normalne, binomialne, Poissona. Infografika z r/datascience.\"\n",
    "        # )\n",
    "        # db.add(test_note3)\n",
    "        # db.commit()\n",
    "        # \n",
    "        # # PoÅ‚Ä…cz materiaÅ‚y z notatkami\n",
    "        # db.add(ImageNote(image_id=test_img1.id, note_id=test_note1.id))\n",
    "        # db.add(ImageNote(image_id=test_img2.id, note_id=test_note2.id))\n",
    "        # db.add(ImageNote(image_id=test_img3.id, note_id=test_note3.id))\n",
    "        # db.commit()\n",
    "        # \n",
    "        # # Wygeneruj embeddingi\n",
    "        # update_image_embeddings(db)\n",
    "        # \n",
    "        # # Testowe zapytanie\n",
    "        # result = answer_question(db, \"PokaÅ¼ materiaÅ‚y o gradient descent i optymalizacji\")\n",
    "        # print(\"ODPOWIEDÅ¹:\", result[\"answer\"])\n",
    "        # print(\"Znalezione materiaÅ‚y:\", result[\"image_ids\"])\n",
    "        \n",
    "        # === OPCJA B: UÅ»YJ WÅASNYCH DANYCH ===\n",
    "        # === [PLACEHOLDER 2] ÅšcieÅ¼ka do notatek tekstowych (pliki .md z podsumowaniami) ===\n",
    "        # notes_root = Path(\"./notatki\")  # ZmieÅ„ na swojÄ… Å›cieÅ¼kÄ™\n",
    "        # index_notes_from_folder(db, notes_root)\n",
    "\n",
    "        # === [PLACEHOLDER 3] ÅšcieÅ¼ka do materiaÅ‚Ã³w z internetu (jpg/png/webp) ===\n",
    "        # images_root = Path(\"./obrazy\")  # â† Tutaj sÄ… zdjÄ™cia notatek z internetu\n",
    "        # PrzykÅ‚adowa struktura:\n",
    "        #   obrazy/\n",
    "        #   â”œâ”€â”€ machine_learning/\n",
    "        #   â”‚   â”œâ”€â”€ lecture_03_slide_15.png\n",
    "        #   â”‚   â””â”€â”€ youtube_screenshot_backprop.jpg\n",
    "        #   â””â”€â”€ statistics/\n",
    "        #       â””â”€â”€ infographic_distributions.png\n",
    "        # \n",
    "        # === [PLACEHOLDER 4] ID projektu (np. nazwa kursu) ===\n",
    "        # index_images_from_folder(db, images_root, default_project_id=\"ML-COURSE-2025\")  # ZmieÅ„ ID\n",
    "\n",
    "        # # PoÅ‚Ä…cz obrazy z notatkami\n",
    "        # link_images_to_notes_by_experiment(db)\n",
    "\n",
    "        # # Wygeneruj embeddingi\n",
    "        # update_image_embeddings(db)\n",
    "\n",
    "        # # Zadaj pytanie\n",
    "        # question = \"PokaÅ¼ eksperymenty z wysokÄ… temperaturÄ… i opisz problemy z pÄ™kaniem materiaÅ‚u.\"\n",
    "        # result = answer_question(db, question)\n",
    "        # print(\"ODPOWIEDÅ¹:\\n\", result[\"answer\"])\n",
    "        # print(\"PowiÄ…zane obrazy:\", result[\"image_ids\"])\n",
    "\n",
    "        print(\n",
    "            \"âœ… Notatnik skonfigurowany dla GitHub Codespace (CPU).\\n\"\n",
    "            \"ðŸ“‹ SprawdÅº placeholdery w komÃ³rce 1 i w tej komÃ³rce.\\n\"\n",
    "            \"ðŸš€ Uruchom komÃ³rki testowe lub odkomentuj sekcje z danymi.\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
